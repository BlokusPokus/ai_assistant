digraph "classes" {
rankdir=BT
charset="utf-8"
"agent_core.core.AgentCore" [color="black", fontcolor="black", label=<{AgentCore|runner<br ALIGN="LEFT"/>|__init__(memory, tools, llm)<br ALIGN="LEFT"/>run(user_input: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.types.state.AgentState" [color="black", fontcolor="black", label=<{AgentState|history : List[Tuple[Any, Any]]<br ALIGN="LEFT"/>memory_context : List[dict]<br ALIGN="LEFT"/>step_count : int<br ALIGN="LEFT"/>user_input : str<br ALIGN="LEFT"/>|__init__(self, user_input: str, memory_context: List[dict], history: List[Tuple[Any, Any]], step_count: int): None<br ALIGN="LEFT"/>add_tool_result(tool_call, result)<br ALIGN="LEFT"/>get_context_window(max_items: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.types.messages.FinalAnswer" [color="black", fontcolor="black", label=<{FinalAnswer|output : str<br ALIGN="LEFT"/>|__init__(output: str)<br ALIGN="LEFT"/>is_final()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.llm.gemini.GeminiLLM" [color="black", fontcolor="black", label=<{GeminiLLM|embedding_model<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>|__init__(api_key: str, model: str)<br ALIGN="LEFT"/>complete(prompt: str, functions: list): dict<br ALIGN="LEFT"/>embed_text(text: str): list[float]<br ALIGN="LEFT"/>parse_response(response: dict): Union[ToolCall, FinalAnswer]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.llm.llm_client.LLMClient" [color="black", fontcolor="black", label=<{LLMClient|model<br ALIGN="LEFT"/>|__init__(model)<br ALIGN="LEFT"/><I>complete</I>(prompt: str, functions: list): dict<br ALIGN="LEFT"/><I>parse_response</I>(response: dict)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.llm.planner.LLMPlanner" [color="black", fontcolor="black", label=<{LLMPlanner|llm_client<br ALIGN="LEFT"/>prompt_builder<br ALIGN="LEFT"/>tool_registry : str<br ALIGN="LEFT"/>|__init__(llm_client: LLMClient, prompt_builder: PromptBuilder, tool_registry: 'ToolRegistry')<br ALIGN="LEFT"/>choose_action(state: 'AgentState'): Union[ToolCall, FinalAnswer]<br ALIGN="LEFT"/>force_finish(state: 'AgentState'): str<br ALIGN="LEFT"/><I>on_tool_completion</I>(tool_name: str, result: Any)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.graph_runner.LangGraphRunner" [color="black", fontcolor="black", label=<{LangGraphRunner|llm<br ALIGN="LEFT"/>max_steps : int<br ALIGN="LEFT"/>memory<br ALIGN="LEFT"/>tools<br ALIGN="LEFT"/>|__init__(memory, tools, llm)<br ALIGN="LEFT"/>run(user_input: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.logs.models.LogEntry" [color="black", fontcolor="black", label=<{LogEntry|agent_response : str<br ALIGN="LEFT"/>memory_used : Optional[list]<br ALIGN="LEFT"/>timestamp : str<br ALIGN="LEFT"/>tool_called : Optional[str]<br ALIGN="LEFT"/>tool_output : Optional[str]<br ALIGN="LEFT"/>user_input : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"agent_core.memory.interface.MemoryInterface" [color="black", fontcolor="black", label=<{MemoryInterface|<br ALIGN="LEFT"/>|<I>add</I>(content: str, metadata: dict)<br ALIGN="LEFT"/><I>query</I>(query: str, k: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.llm.prompt_builder.PromptBuilder" [color="black", fontcolor="black", label=<{PromptBuilder|tool_registry : str<br ALIGN="LEFT"/>|__init__(tool_registry: 'ToolRegistry')<br ALIGN="LEFT"/>build(state: 'AgentState'): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.tools.base.Tool" [color="black", fontcolor="black", label=<{Tool|description : str<br ALIGN="LEFT"/>func : Callable<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>parameters : Dict<br ALIGN="LEFT"/>|__init__(name: str, func: Callable, description: str, parameters: Dict)<br ALIGN="LEFT"/>execute()<br ALIGN="LEFT"/>validate_args(kwargs: Dict[str, Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.types.messages.ToolCall" [color="black", fontcolor="black", label=<{ToolCall|args : dict<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|__init__(name: str, args: dict)<br ALIGN="LEFT"/>is_final()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.tools.base.ToolRegistry" [color="black", fontcolor="black", label=<{ToolRegistry|_llm_planner : NoneType, str<br ALIGN="LEFT"/>tools : dict<br ALIGN="LEFT"/>|__init__()<br ALIGN="LEFT"/>get_schema(): dict<br ALIGN="LEFT"/>register(tool: Tool)<br ALIGN="LEFT"/>run_tool(name: str)<br ALIGN="LEFT"/>set_planner(planner: 'LLMPlanner')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.memory.vector_memory.VectorMemory" [color="black", fontcolor="black", label=<{VectorMemory|client<br ALIGN="LEFT"/>collection<br ALIGN="LEFT"/>|__init__(client)<br ALIGN="LEFT"/>add(content: str, metadata: dict)<br ALIGN="LEFT"/>query(query: str, k: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"agent_core.llm.gemini.GeminiLLM" -> "agent_core.llm.llm_client.LLMClient" [arrowhead="empty", arrowtail="none"];
"agent_core.memory.vector_memory.VectorMemory" -> "agent_core.memory.interface.MemoryInterface" [arrowhead="empty", arrowtail="none"];
"agent_core.graph_runner.LangGraphRunner" -> "agent_core.core.AgentCore" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="runner", style="solid"];
"agent_core.llm.llm_client.LLMClient" -> "agent_core.llm.planner.LLMPlanner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="llm_client", style="solid"];
"agent_core.llm.prompt_builder.PromptBuilder" -> "agent_core.llm.planner.LLMPlanner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="prompt_builder", style="solid"];
}
